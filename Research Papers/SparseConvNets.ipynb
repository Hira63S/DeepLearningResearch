{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Convolutional Networks\n",
    "\n",
    "### A detailed overview of the Sparse ConvNets for 4D Spatio-Temporal ConvNets\n",
    "[Paper Link](https://arxiv.org/pdf/1904.08755.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse ConvNets are ideal for 3D data processing because the parameters increase exponentially with the increase in dimensions. For exampl,e for a 2D conv, the kernel size of 5 requires 5^^2 = 25 weights, which increase to 5^3 = 125 in a 3D cube and 625 in a 4D tesseract.\n",
    "Using the generalized sparse convolutions, we use custom kernels with non-(hyper)-cubic shapes.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from 4D ConvNets are not consistent across time and space when using generalized sparse ConvNets. So, high-dimensional conditional random fields defined in a 7D trilateral space (space-time-color) are proposed with a stationary pairwise consistency function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using convolution for temporal axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since images have a lot of irrelevant data, we transform the data into sparse tensors data. The matrix contains 4d coordinates as C: {(x_i, y_i, z_i, t_i)}_i_ and a set of features as: F = {f_i}_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, a sparse tensor is a multi-dimensional array with most of the elements at zero. We represent a sparse tensor with two matrices: C matric contains the coordinates where there are non-zero values and F matrix is actual non-zero value (for example, pixels etc.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Maps\n",
    "\n",
    "To figure out how a sparse tensor maps to another sparse tensor as a result of convolution, we need to have kernel maps taht keep track of which coordinate in the input sparse tensor is mapped to which coordinate in the output sparse tensor. We do so by representing a map as a pair of lists of integers: the in map I and the out map O. Any integer in the I map indicates the row index of the coordinate matrix or feature matrix of the input sparse tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernels\n",
    "### Issues with multi-dimensional convolutions:\n",
    "- The computational cost and parameters in the network increases exponentially\n",
    "- The networks do not have an incentive to make the predictions consistent thorugh the space and time with conventional cross-entropy loss.\n",
    "### Solutions:\n",
    "- Use of special property of generalized sparse convs and make use of the non-conventional kernal shapes.\n",
    "- for spatio-temporal consistency, a high-dimensional conditional random field (7D space-time-color space) is proposed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesseract Kernel and Hybrid Kernel\n",
    "- We use kernel offsets N^^D of the generalized sparse convolution to implement the hybrid kernel\n",
    "- Cubic kernel is used to capture the spatial information i.e. 9 blocks. Hybercube is one with 3x3 dimension (like a rubik's cube). The cross kernel is used for temporal dimension. SO we use a hybrid kernel that is 3x3 but has a cross-shaped kernel imposed on top of it so that we are also able to take care of the temporal dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trilateral Stationary-CRF\n",
    "\n",
    "For semantic segmentation, we use cross-entropy loss is applied for each pixel or voxel.\n",
    "Conditional Random Field(CRF): Also used in 2D images with 3D color channels. \n",
    "For 3D videos, a trilateral space is used that consists of 3D space, 1D time, and 3D chromatic space. The color space creates a \"spatial\" gap between points with differnet colors that are spatially adjacent (e.g. on a boundary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.LongTensor([[0, 1, 1],\n",
    "                     [2, 0, 2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.FloatTensor([3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3.],\n",
       "        [4., 0., 5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sparse.FloatTensor(i, v, torch.Size([2,3])).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
