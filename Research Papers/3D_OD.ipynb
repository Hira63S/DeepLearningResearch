{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Object Detection Preparation for Tesla\n",
    "\n",
    "Vision-based approach\n",
    "no lidar, no HD map\n",
    "\n",
    "Bird-eye view networks.\n",
    "\n",
    "\n",
    "Neural Networks for FSD:\n",
    "Take an image, have it go through the shared backbone and make predictions about the image in the pixel space. \n",
    "\n",
    "For example: Taking edges, take predictions of road edge task from all 8 cameras.\n",
    "can't drive on the raw predictions of the edges in 2D pixel space. Project it out to a bird's eye view.\n",
    "Project them out into 3D and do an occupency tracker.\n",
    "Stitch them across camera and across time.\n",
    "This is where Software 2.0 comes up. software 1.0 code, \n",
    "Take the functionality from 1.0 code base and put it into software 2.0 code.\n",
    "In the case of road edges, \n",
    "bird's eye view networks -> Take all the camera, feed through backbone, have neural net fusion layer, that stitches up the feature maps across the different views and does the prediction from image space to bird's eye view and temporal module that smoothes out the predictions. dead net declutter that does a top-down approach\n",
    "\n",
    "Depth-per pixel to make the prediction.\n",
    "Bird's eye view networks. \n",
    "\n",
    "Depth predictions -- pseudolidar approach\n",
    "predict the depth per pixel and cast it out\n",
    "self-supervised techniques \n",
    "\n",
    "## Achieving depth from image\n",
    "self-superised tech -> predict a depth on the image, cast the pixels in 3D. and reproject them into camera views at the same time but different camera, or you can project them into future frames. \n",
    "Photometric loss. \n",
    "To make everything consistent is to predict the correct depth. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird-eye view networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used to perform convolutions in CNNs to compute both the spatial and tral dimensions. \n",
    "- 3D convolution convolves the 3D filters to the cube performed by stacking the subsequent frames on top of each other so we are able to connect contiguous rame together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
