{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointNets -> Frustum PointNets\n",
    "The later builds on the concepts from the first one so we are going to take a look at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet:\n",
    "Takes in point cloud as input and outputs either class labels for the entire input or per point segment/part labels for eeach point of the input.\n",
    "Each point is processed independently and is represented by just three coordinates (x, y, z).\n",
    "\n",
    "1. Consumes unordered point sets in 3D.\n",
    "2. 3D space classification, shape part segmentation and scene semantic parsing\n",
    "3. Detailed empirical and theoretical analysis on the stability and efficiency of our method\n",
    "4. Illustratio of 3D features computed by the selected neurons in the net and develop intuitive explanations on it's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "Point Cloud: {P_i | i = 1, .... , n}\n",
    "Where each point P_i is a vecctor of its (x, y, z) coordinates as well as additional information like color channels etc. \n",
    "For simplicity, we only used the (x,y,z) coordinates as the point's channels. \n",
    "\n",
    "\n",
    "### Euclidean Space:\n",
    "Where points are represented by coordinates (one for each dimension) and the distance between teh points is given by distance formula.\n",
    "\n",
    "In Euclidean Space, the point sets have following properties: <br/>\n",
    "\n",
    "**Unordered.** Unlike Pixel arrays in images, the point sets are random without specific order. So, the network needs to be able to consume N 3D point sets to be invariant to N! permutations of the input set in data feeding order. <br/>\n",
    "**Interaction among points.** The neighboring points are important for other points because it is in euclidean space and each point is connected to other via distance. <br/>\n",
    "**Invariance under transformations.** If we transform the point clouds, they should be invariant to certain transformations. For example, rotating and translating points all together should not modify the global point cloud category nor the segmentations of the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointNet Architecture\n",
    "\n",
    "![PointNet](PointNet.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PointNet Architecture uses both classification and segmentation network. The input is sampled from the point net cloud and passed into the classification network. \n",
    "\n",
    "**Symmetry Function for Unordered Input:**\n",
    "To make the model invariant to input permutations, three strategies exist:\n",
    "1. Sort input into a canonical order - \n",
    "2. Treat the input as a sequence to train an RNN and augment the training data with all kinds of permutations for the point cloud.\n",
    "3. Use a simple, symmetric function to aggregate the information from each point. i.e.A symmetric function takes n vectors as input and the output is invariant to what the n vectors were. For example, + and * in binary operation are symmetric functions.\n",
    "\n",
    "**Sorting** Issue with sorting is that there is not really an ordering that is stable with respect to the point perturbations that you can have in the high dimensional spaces. Asking for the point perturbations to keep the same order is the same as saying that the points should keep spacial proximity as the dimension reduce. \n",
    "**RNNs** Using RNNs is also not ideal because they work fine with small sequences but having them work with large sequences that point clouds are, is not ideal. \n",
    "**Symmetric function** takes in an N dimensional input and outputs in a specific way so that it is invariant of what it is intaking.\n",
    "Simple model: the transformed inputs are passed into an h function which is basically the perceptron network and then we perform the activation function and max pooling. Through a collection of different h functions, we can learn different properties of the set. (basically a neural network... duh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
