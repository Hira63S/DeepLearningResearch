{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS231N - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor model could use two classification losses:\n",
    "\n",
    "#### L1 distance loss: </br>\n",
    "\n",
    "            distance(l1, l2) = sum(np.abs(l1 - l2))\n",
    "            \n",
    "L1 distance is basically the subtraction of every pixel value between two images and summing up the absolute difference.\n",
    "\n",
    "#### L2 distance loss: </br>\n",
    "            distance(l1, l2) = sqrt(np.sum(l1-l2)**2))\n",
    "            Takes the difference between the pixels, squares them and adds them up and then square roots them.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 loss:\n",
    "\n",
    "distances = np.sum(np.abs(l1 - l2))\n",
    "\n",
    "# l2 loss:\n",
    "distances = np.sqrt(np.sum(l1-l2)**2)\n",
    "distances = np.sqrt(np.sum(np.square(l1-l2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between nearest neighbor and k-nearest neighbor: \n",
    "Nearest neighbor tries to find the difference between the test images and all the other images in the dataset. Tries to find the closest image from the dataset. But the k-nearest neighbor classifier finds the k closest images in the dataset and have them vote on the label of the test image. Closest image vs. closest cluster of images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons of KNNs\n",
    "\n",
    "Obviously the model compares the pixels between images. It is quick to train but takes forever for test set. Also, does not learn features and since it is just comparing pixel values, it could potentially label two very different object the same if they have a large similar background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification\n",
    "\n",
    "A **Score function** and a **Loss Function** is used for linear classification.\n",
    "\n",
    "*Score Function* creates a map from raw data points the class scores and the loss function figures out the agreement between the predicted scores and the ground truth labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.2*56)+("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-96.8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.2*56)+(-0.5*231)+(0.1*24)+(2*2) + 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_i(x, y, W):\n",
    "    \"\"\" Unvectorized version. Compute the multiclass SVM loss for a single example (x, y)\n",
    "    - x is a column vector representing an image i.e. # of pixels x 1\n",
    "    - y is a ninteger giving index of correct class (i.e. between 0 and 9 in CIFAR-10)\n",
    "    - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)\n",
    "    \"\"\"\n",
    "    delta = 1.0 # the hyperparameter that the loss function wants the correct class label to be different\n",
    "    # by at least this value\n",
    "    scores = W.dot(x)\n",
    "    correct_class_score = scores[y]\n",
    "    D = W.shape[0]\n",
    "    loss_i = 0.0\n",
    "    for j in range(D):\n",
    "        if j == y:\n",
    "            continue\n",
    "        loss_i += max(0, scores[j] - correct_class_score + delta)\n",
    "    return loss_i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_i_v(x, y, W):\n",
    "    \n",
    "    delta = 1.0\n",
    "    scores = W.dot(x)\n",
    "    \n",
    "    margins = np.max(0, scores - scores[y] + delta)\n",
    "    \n",
    "    margins[y] = 0\n",
    "    loss_i = np.sum(margins)\n",
    "    return loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(x, y, W):\n",
    "    \n",
    "    delta = 1.0\n",
    "    \n",
    "    for i in range(x):\n",
    "        scores = W.dot(i)\n",
    "        margins = np.max(0, scores - scores[y] + delta)\n",
    "        \n",
    "        # margins at y are 0 because that is the correct class label\n",
    "        \n",
    "        margins[y] = 0\n",
    "        \n",
    "        loss_i = np.sum(margins)\n",
    "        \n",
    "    return loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
